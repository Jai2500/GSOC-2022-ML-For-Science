{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6101ff24-5a13-4032-a8c8-1fe5b09bad82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jai.bardhan/anaconda3/envs/ml/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "from torchmetrics import AUROC, ROC, Accuracy\n",
    "from dataset import ImageDatasetFromParquet\n",
    "import torch_geometric\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f25133f9-80ea-4ddc-9a27-38e4e2055728",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "VAL_BATCH_SIZE = 64\n",
    "TEST_BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b01ab3-af1b-4057-9326-887af36865c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_transform = [\n",
    "    #T.Resize(224),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomVerticalFlip(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "    # T.RandomAdjustSharpness(0.5, p=0.1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa6c99e3-d6dc-4e70-93db-ddae162255ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_0_path = \"/scratch/gsoc/parquet_ds/QCDToGGQQ_IMGjet_RH1all_jet0_run0_n36272.test.snappy.parquet\"\n",
    "run_1_path = \"/scratch/gsoc/parquet_ds/QCDToGGQQ_IMGjet_RH1all_jet0_run1_n47540.test.snappy.parquet\"\n",
    "run_2_path = \"/scratch/gsoc/parquet_ds/QCDToGGQQ_IMGjet_RH1all_jet0_run2_n55494.test.snappy.parquet\"\n",
    "\n",
    "\n",
    "run_0_ds = ImageDatasetFromParquet(run_0_path, transforms=required_transform, return_regress=True)\n",
    "run_1_ds = ImageDatasetFromParquet(run_1_path, transforms=required_transform, return_regress=True)\n",
    "run_2_ds = ImageDatasetFromParquet(run_2_path, transforms=required_transform, return_regress=True)\n",
    "\n",
    "combined_dset = torch.utils.data.ConcatDataset([run_0_ds, run_1_ds, run_2_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45382b67-3e31-4cc3-b819-afc42a33d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.15\n",
    "\n",
    "test_size = int(len(combined_dset) * TEST_SIZE)\n",
    "val_size = int(len(combined_dset) * VAL_SIZE)\n",
    "train_size = len(combined_dset) - val_size - test_size\n",
    "\n",
    "train_dset, val_dset, test_dset = torch.utils.data.random_split(\n",
    "    combined_dset,\n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a6b880d-bca3-4acc-b87a-9891666f9440",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dset.required_transforms = [T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "012f5c67-c96a-4034-a99b-bef9484724b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dset, shuffle=True, batch_size=TRAIN_BATCH_SIZE, pin_memory=True, num_workers=16)\n",
    "val_loader = torch.utils.data.DataLoader(val_dset, shuffle=False, batch_size=VAL_BATCH_SIZE, pin_memory=True, num_workers=16)\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, shuffle=False, batch_size=TEST_BATCH_SIZE, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e2f1dd0-b9e4-4ed1-b2e6-aa88c0fa75b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60291f91-fbd6-4a12-9b00-bde20e3253f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressModel(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        in_features = self.model.fc.in_features\n",
    "        self.model.fc = torch.nn.Identity()\n",
    "\n",
    "        self.out_lin = torch.nn.Sequential(\n",
    "          torch.nn.Linear(in_features + 1, in_features // 2, bias=True),\n",
    "          torch.nn.BatchNorm1d(in_features // 2),\n",
    "          torch.nn.SiLU(),\n",
    "          torch.nn.Dropout(),\n",
    "          torch.nn.Linear(in_features // 2, in_features // 4, bias=True),\n",
    "          torch.nn.BatchNorm1d(in_features // 4),\n",
    "          torch.nn.SiLU(),\n",
    "          torch.nn.Dropout(),\n",
    "          torch.nn.Linear(in_features // 4, 1, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, X, pt):\n",
    "        out = self.model(X)\n",
    "        out = torch.cat([out, pt.unsqueeze(-1)], dim=1)\n",
    "        return self.out_lin(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50cd8d28-4d20-42b7-bdec-e2dd572720c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(device):\n",
    "    model = RegressModel(\n",
    "        model=torchvision.models.resnet50(pretrained=True)\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e38a145c-d03f-4033-8d07-cb46c711509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr):\n",
    "    return torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50e13eb7-284b-40a8-bb4b-7eaa11efe23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, model, criterion, optimizer, train_loader, val_loader, device):\n",
    "    best_model = copy.deepcopy(model).to('cpu', non_blocking=True)\n",
    "    best_val_loss = float('inf')\n",
    "    val_loss_avg_meter = AverageMeter()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        tqdm_iter = tqdm(train_loader, total=len(train_loader))\n",
    "        tqdm_iter.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "        for it, batch in enumerate(tqdm_iter):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            X, pt, m0 = batch['X_jets'].float(), batch['pt'].float(), batch['m0'].float()\n",
    "\n",
    "            X = X.to(device, non_blocking=True)\n",
    "            pt = pt.to(device, non_blocking=True)\n",
    "            m0 = m0.to(device, non_blocking=True)\n",
    "\n",
    "            out = model(X, pt)\n",
    "\n",
    "            loss = criterion(out, m0.unsqueeze(-1))\n",
    "\n",
    "            tqdm_iter.set_postfix(loss=loss.item())\n",
    "            wandb.log({\n",
    "                \"train_mse_loss\": loss.item(),\n",
    "                \"train_step\": (it * TRAIN_BATCH_SIZE) + epoch * train_size\n",
    "            })\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_tqdm_iter = tqdm(val_loader, total=len(val_loader))\n",
    "        val_tqdm_iter.set_description(f\"Validation Epoch {epoch}\")\n",
    "        val_loss_avg_meter.reset()\n",
    "\n",
    "        for it, batch in enumerate(val_tqdm_iter):\n",
    "            with torch.no_grad():\n",
    "                X, pt, m0 = batch['X_jets'].float(), batch['pt'].float(), batch['m0'].float()\n",
    "\n",
    "                X = X.to(device, non_blocking=True)\n",
    "                pt = pt.to(device, non_blocking=True)\n",
    "                m0 = m0.to(device, non_blocking=True)\n",
    "\n",
    "                out = model(X, pt)\n",
    "\n",
    "                loss = criterion(out, m0.unsqueeze(-1))\n",
    "\n",
    "                val_tqdm_iter.set_postfix(loss=loss.item())\n",
    "                wandb.log({\n",
    "                    \"val_mse_loss\": loss.item(),\n",
    "                    \"val_step\": (it * VAL_BATCH_SIZE) + epoch * val_size\n",
    "                })\n",
    "                val_loss_avg_meter.update(loss.item(), out.size(0))\n",
    "\n",
    "        if val_loss_avg_meter.avg < best_val_loss:\n",
    "            best_model = copy.deepcopy(model).to('cpu', non_blocking=True)\n",
    "            best_val_loss = val_loss_avg_meter.avg\n",
    "                \n",
    "    del model\n",
    "\n",
    "    return best_model.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05947769-d516-41cd-8f1c-4c648c5c2e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss_avg_meter = AverageMeter()\n",
    "    tqdm_iter = tqdm(test_loader, total=len(test_loader))\n",
    "    \n",
    "    pred_list = []\n",
    "    ground_truth_list = []\n",
    "    \n",
    "    \n",
    "    for it, batch in enumerate(tqdm_iter):\n",
    "        with torch.no_grad():\n",
    "            X, pt, m0 = batch['X_jets'].float(), batch['pt'].float(), batch['m0'].float()\n",
    "\n",
    "            X = X.to(device, non_blocking=True)\n",
    "            pt = pt.to(device, non_blocking=True)\n",
    "            m0 = m0.to(device, non_blocking=True)\n",
    "\n",
    "            out = model(X, pt)\n",
    "\n",
    "            loss = criterion(out, m0.unsqueeze(-1))\n",
    "                        \n",
    "            tqdm_iter.set_postfix(loss=loss.item())\n",
    "            \n",
    "            test_loss_avg_meter.update(loss.item(), out.size(0))\n",
    "            \n",
    "    return test_loss_avg_meter.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d08211a4-fe7f-4174-a937-80e61346300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(run_name):\n",
    "    wandb.init(name=run_name, project='gsoc-submission')\n",
    "    \n",
    "    model = get_model(DEVICE)\n",
    "    \n",
    "    opt = get_optimizer(model, lr=3e-4)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    model = train(NUM_EPOCHS, model, criterion, opt, train_loader, val_loader, DEVICE)\n",
    "    test_loss = test(model, test_loader, criterion, DEVICE)\n",
    "    print(f\"Model on Test dataset: Loss: {test_loss}\")\n",
    "    \n",
    "    wandb.finish()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b53fa625-035f-43cc-a8a2-8287edcd456a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjai-bardhan\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jai.bardhan/GSOC/Task2/wandb/run-20220424_004625-224qvwvz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jai-bardhan/gsoc-submission/runs/224qvwvz\" target=\"_blank\">task_2_regress_resnet</a></strong> to <a href=\"https://wandb.ai/jai-bardhan/gsoc-submission\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1415/1415 [07:06<00:00,  3.32it/s, loss=11]  \n",
      "Validation Epoch 0: 100%|██████████| 327/327 [01:46<00:00,  3.08it/s, loss=11.7]\n",
      "Epoch 1: 100%|██████████| 1415/1415 [07:05<00:00,  3.33it/s, loss=11.6]\n",
      "Validation Epoch 1: 100%|██████████| 327/327 [01:47<00:00,  3.03it/s, loss=6.95]\n",
      "Epoch 2: 100%|██████████| 1415/1415 [06:57<00:00,  3.39it/s, loss=10.7]\n",
      "Validation Epoch 2: 100%|██████████| 327/327 [01:42<00:00,  3.18it/s, loss=5.04]\n",
      "Epoch 3: 100%|██████████| 1415/1415 [06:52<00:00,  3.43it/s, loss=15.6]\n",
      "Validation Epoch 3: 100%|██████████| 327/327 [01:38<00:00,  3.31it/s, loss=9.03]\n",
      "Epoch 4: 100%|██████████| 1415/1415 [06:59<00:00,  3.37it/s, loss=9.12]\n",
      "Validation Epoch 4: 100%|██████████| 327/327 [01:44<00:00,  3.13it/s, loss=6.45]\n",
      "100%|██████████| 436/436 [02:17<00:00,  3.18it/s, loss=6.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on Test dataset: Loss: 5.6690891087771895\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_mse_loss</td><td>█▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_mse_loss</td><td>█▆▄█▆▅▇▆▃▃▄▁▆▄▂▄▃▃▁▄▄▂▂▃▆▄▅▃▇▄▅▅▃▁▂▂▂▁▁▂</td></tr><tr><td>val_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_mse_loss</td><td>9.11817</td></tr><tr><td>train_step</td><td>452696</td></tr><tr><td>val_mse_loss</td><td>6.44981</td></tr><tr><td>val_step</td><td>104444</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">task_2_regress_resnet</strong>: <a href=\"https://wandb.ai/jai-bardhan/gsoc-submission/runs/224qvwvz\" target=\"_blank\">https://wandb.ai/jai-bardhan/gsoc-submission/runs/224qvwvz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220424_004625-224qvwvz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = main('task_2_regress_resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c6594be-d031-44ee-b186-6fc3fce0c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"task_2_regress_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('ml': conda)",
   "language": "python",
   "name": "python38564bitmlconda30107212453f4d5ba50ee3732a99980f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
